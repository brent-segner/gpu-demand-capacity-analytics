# Prompts Used to Generate This Project

## Overview

This document records the key prompts and instructions used to generate this project via Claude (Anthropic). Transparency about the generation process allows community members to understand the design decisions and suggest improvements.

---

## Project Constitution (Guiding Principles)

The following non-negotiable requirements guided all generation:

```
1. ALL datasets are synthetic and generated by code in-repo (no real cluster data, no copied samples).

2. The notebook must run end-to-end on a laptop (CPU-only) using synthetic CSV/Parquet generated locally.

3. Every chart must have a clear caption + "so what" interpretation.

4. Every derived metric must be defined in plain English and in a small data dictionary.

5. Provide "assumptions & limitations" and explicitly call out where real-world wiring differs (label joins, scrape intervals, missing labels, etc.).
```

---

## Prompt 1: Project Concept

> I want to create a high-quality, open-source analysis project that can be shared publicly via GitHub to gather feedback and consensus from a broad external audience (platform engineering, ML infrastructure, and FinOps practitioners). 
>
> The goal of the project is to demonstrate—using synthetic data only—how a combination of Kubernetes Kueue queue metrics, Prometheus-based cluster telemetry, and NVIDIA DCGM GPU metrics can be used together to identify imbalances between user demand and available capacity across GPU node pools (nodegroups) in GenAI-focused Kubernetes clusters.
>
> The core analytical question is: where, when, and why does queued or unmet workload demand diverge from actual GPU capacity or effective utilization at the node pool level?

---

## Prompt 2: Repository Structure

> Propose a repo structure (folders + filenames) for: data generation, notebooks, reusable analysis utilities, and docs.
>
> Include: README.md, PROMPTS.md, DATA_DICTIONARY.md, CONTRIBUTING.md, and an "RFC template" file to gather community consensus.
>
> Keep it minimal but professional. Provide the full directory tree.

---

## Prompt 3: Synthetic Data Generator

> Implement a Python module that generates the synthetic datasets exactly as specified.
>
> Requirements:
> - Deterministic with a random seed.
> - Parameterized scenario selection (balanced / demand-constrained / fragmentation).
> - Writes to data/synthetic/ in CSV (or Parquet) with a "manifest.json" that records seed, scenario, row counts, and timestamps.
> - Add basic validation checks (no negative values, percent ranges, monotonic timestamps, etc.).
>
> Provide complete code files and a short usage section for the README.

---

## Prompt 4: Notebook Outline (Before Implementation)

> Create a notebook outline (section headers + what each section proves) that:
> 1. Loads synthetic data,
> 2. Builds a unified time-indexed model,
> 3. Computes "demand vs capacity imbalance" per nodegroup,
> 4. Identifies top contributors (which local queues / namespaces),
> 5. Produces 6–10 charts with captions and interpretation,
> 6. Ends with "what actions would you take" and "what additional data would you want."
>
> Include the exact derived metrics you will compute and their formulas.

---

## Prompt 5: Notebook Implementation

> Implement the notebook exactly following the outline.
>
> Constraints:
> - Use pandas + matplotlib/plotly (choose one and be consistent).
> - Every chart has: title, axis labels, units, and a 2–3 sentence interpretation.
> - Include helper functions in /src/ (the notebook should not be 1,500 lines of inline code).
> - Include a final "Repro steps" cell and a "Sanity checks" cell (row counts, missing labels, etc.).

---

## Prompt 6: Imbalance Metrics Definition

> Propose 2–3 candidate "imbalance" metrics that combine:
> - queue demand (pending + wait times + resource usage) and
> - capacity signals (nodepool GPU count + DCGM utilization/power + optional memory pressure).
>
> For each candidate:
> - Provide formula,
> - What it's sensitive to,
> - Failure modes / false positives,
> - What operator action it suggests.
>
> Then recommend one as the default and keep the others as documented alternatives.
>
> Tie this back to the Kueue metrics that quantify pending and wait-time.

---

## Prompt 7: README Documentation

> Write a detailed README for an external audience (FinOps + platform + ML engineers).
>
> Must include:
> - Project goal in 5 lines
> - Architecture diagram (ASCII is fine) showing metric sources → synthetic generator → notebook → outputs
> - Data inputs + label contract
> - Step-by-step logic of the analysis (mirrors the notebook)
> - How to run (create venv, install, generate data, run notebook)
> - Interpreting results (what "imbalance" means)
> - Limitations + what real-world wiring would require
> - How to provide feedback / propose changes (link to RFC template)

---

## Prompt 8: Consensus Workflow

> Create:
> - docs/RFC_TEMPLATE.md with sections: Problem, Proposed metric change, Rationale, Alternatives, Expected impact, Validation plan.
> - CONTRIBUTING.md that tells people exactly how to propose new metrics, new scenarios, or new charts.
> - A GitHub Issues taxonomy: labels and issue templates (bug / metric proposal / data schema change / visualization request).

---

## Naming Convention Standardization

> Standardize naming conventions so it is easy to follow for users:
> - Demand signals = Kueue pending counts + wait times + (optional) resource usage
> - Capacity signals = nodepool inventory (GPU count) + DCGM utilization/power/memory/profiling
> - Imbalance = a defined function that compares those two at the nodepool/nodegroup level, over time

---

## Generation Process Notes

1. **Iterative refinement**: Multiple rounds of generation and review were used
2. **Manual curation**: Some generated content was manually edited for clarity
3. **Consistency checks**: Cross-references between documents were verified
4. **Code testing**: Generated code was executed to verify functionality

---

## Reproduction

To regenerate this project structure:

1. Use Claude or similar LLM
2. Provide the Project Constitution first
3. Execute prompts sequentially
4. Validate outputs against non-negotiables
5. Iterate as needed

---

## Contributing Prompt Improvements

If you believe the prompts could be improved:

1. Open an issue describing the limitation
2. Propose improved prompt wording
3. Show expected vs actual output
4. Submit via the RFC process for significant changes

---

*This transparency enables community review and improvement of the generation process itself.*
