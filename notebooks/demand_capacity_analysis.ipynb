{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Demand vs Capacity Analytics\n",
    "\n",
    "## Identifying Imbalances Between Workload Demand and GPU Capacity\n",
    "\n",
    "This notebook demonstrates how to analyze GPU demand-versus-capacity imbalances in Kueue-managed Kubernetes clusters using:\n",
    "\n",
    "- **Kueue LocalQueue metrics** (demand signals)\n",
    "- **NVIDIA DCGM metrics** (capacity/efficiency signals)\n",
    "- **Nodepool state** (inventory)\n",
    "\n",
    "### Core Analytical Question\n",
    "\n",
    "> **Where, when, and why does queued or unmet workload demand diverge from actual GPU capacity or effective utilization at the node pool level?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path('.').absolute()))\n",
    "\n",
    "# Import project modules\n",
    "from src.analysis.metrics import add_efficiency_metrics, GPU_SPECS\n",
    "from src.analysis.imbalance import (\n",
    "    calculate_all_imbalance_metrics,\n",
    "    identify_top_contributors,\n",
    ")\n",
    "from src.analysis.aggregations import build_unified_model, create_time_series_summary\n",
    "from src.visualization.charts import (\n",
    "    plot_utilization_vs_power_intensity,\n",
    "    plot_imbalance_heatmap,\n",
    "    plot_demand_vs_capacity_timeseries,\n",
    "    plot_top_contributors,\n",
    "    plot_efficiency_distribution,\n",
    ")\n",
    "from src.visualization.styles import setup_matplotlib_defaults, COLORS\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "setup_matplotlib_defaults()\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Validate Synthetic Data\n",
    "\n",
    "Load the three synthetic datasets:\n",
    "- **kueue_metrics.csv**: Queue demand signals (pending workloads, wait times)\n",
    "- **dcgm_metrics.csv**: GPU efficiency signals (utilization, power, memory)\n",
    "- **nodepool_state.csv**: Capacity inventory (GPU counts per nodegroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "DATA_DIR = Path('data/synthetic')\n",
    "\n",
    "kueue_df = pd.read_csv(DATA_DIR / 'kueue_metrics.csv', parse_dates=['timestamp', 'timestamp_hour'])\n",
    "dcgm_df = pd.read_csv(DATA_DIR / 'dcgm_metrics.csv', parse_dates=['timestamp', 'timestamp_hour'])\n",
    "nodepool_df = pd.read_csv(DATA_DIR / 'nodepool_state.csv', parse_dates=['timestamp', 'timestamp_hour'])\n",
    "\n",
    "print(\"Datasets Loaded:\")\n",
    "print(f\"  Kueue metrics: {len(kueue_df):,} rows\")\n",
    "print(f\"  DCGM metrics: {len(dcgm_df):,} rows\")\n",
    "print(f\"  Nodepool state: {len(nodepool_df):,} rows\")\n",
    "print(f\"\\nDate range: {kueue_df['timestamp'].min()} to {kueue_df['timestamp'].max()}\")\n",
    "print(f\"\\nNodegroups: {kueue_df['nodegroup'].unique().tolist()}\")\n",
    "print(f\"GPU Models: {dcgm_df['gpu_model'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "print(\"=\" * 60)\n",
    "print(\"SANITY CHECKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for nulls\n",
    "print(f\"\\nNull values in Kueue: {kueue_df.isnull().sum().sum()}\")\n",
    "print(f\"Null values in DCGM: {dcgm_df.isnull().sum().sum()}\")\n",
    "print(f\"Null values in Nodepool: {nodepool_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Check ranges\n",
    "print(f\"\\nGPU utilization range: {dcgm_df['gpu_utilization_pct'].min():.1f}% - {dcgm_df['gpu_utilization_pct'].max():.1f}%\")\n",
    "print(f\"Power usage range: {dcgm_df['power_usage_watts'].min():.0f}W - {dcgm_df['power_usage_watts'].max():.0f}W\")\n",
    "print(f\"Pending workloads range: {kueue_df['pending_workloads'].min()} - {kueue_df['pending_workloads'].max()}\")\n",
    "\n",
    "# Check label consistency\n",
    "kueue_nodegroups = set(kueue_df['nodegroup'].unique())\n",
    "dcgm_nodegroups = set(dcgm_df['nodegroup'].unique())\n",
    "nodepool_nodegroups = set(nodepool_df['nodegroup'].unique())\n",
    "\n",
    "print(f\"\\nNodegroup consistency:\")\n",
    "print(f\"  Kueue nodegroups: {len(kueue_nodegroups)}\")\n",
    "print(f\"  DCGM nodegroups: {len(dcgm_nodegroups)}\")\n",
    "print(f\"  Nodepool nodegroups: {len(nodepool_nodegroups)}\")\n",
    "print(f\"  All match: {kueue_nodegroups == dcgm_nodegroups == nodepool_nodegroups}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Efficiency Metrics\n",
    "\n",
    "Add derived efficiency metrics to the DCGM data:\n",
    "\n",
    "- **Power Intensity Factor (PIF)**: `power / max_power` - proxy for actual compute work\n",
    "- **Realized TFLOPS**: `achievable_tflops × PIF` - actual throughput\n",
    "- **RFU %**: `(realized / achievable) × 100` - true efficiency\n",
    "- **Efficiency Gap**: `GPU_util% - RFU%` - hidden waste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add efficiency metrics\n",
    "dcgm_df = add_efficiency_metrics(dcgm_df)\n",
    "\n",
    "print(\"Efficiency Metrics Added:\")\n",
    "print(f\"  - power_intensity_factor (PIF)\")\n",
    "print(f\"  - realized_tflops\")\n",
    "print(f\"  - rfu_pct (Realized TFLOPS Utilization %)\")\n",
    "print(f\"  - efficiency_gap\")\n",
    "print(f\"  - efficiency_class\")\n",
    "\n",
    "print(\"\\nEfficiency Summary:\")\n",
    "print(f\"  Average GPU Utilization: {dcgm_df['gpu_utilization_pct'].mean():.1f}%\")\n",
    "print(f\"  Average PIF: {dcgm_df['power_intensity_factor'].mean():.3f}\")\n",
    "print(f\"  Average RFU: {dcgm_df['rfu_pct'].mean():.1f}%\")\n",
    "print(f\"  Average Efficiency Gap: {dcgm_df['efficiency_gap'].mean():.1f} percentage points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiency class distribution\n",
    "print(\"Efficiency Class Distribution:\")\n",
    "print(\"-\" * 40)\n",
    "for cls, count in dcgm_df['efficiency_class'].value_counts().items():\n",
    "    pct = count / len(dcgm_df) * 100\n",
    "    print(f\"  {cls:15} {count:>8,} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization: GPU Utilization vs Power Intensity\n",
    "\n",
    "This critical chart reveals the relationship between reported utilization and actual computational work.\n",
    "\n",
    "**Key patterns:**\n",
    "- **Upper-right (green)**: Efficient - busy AND productive\n",
    "- **Lower-right (red)**: Bottlenecked - busy but stalled on I/O\n",
    "- **Lower-left (gray)**: Idle - minimal activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_utilization_vs_power_intensity(dcgm_df, sample_size=5000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So What?\n",
    "\n",
    "Points in the **lower-right quadrant** (high utilization, low PIF) represent GPUs that appear busy but aren't doing productive work. These are likely:\n",
    "- Waiting for data from slow storage\n",
    "- Stalled on network synchronization\n",
    "- Memory-bound with poor access patterns\n",
    "\n",
    "**Action**: Investigate bottlenecked workloads for data pipeline optimization opportunities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization: Efficiency Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_efficiency_distribution(dcgm_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So What?\n",
    "\n",
    "The proportion of \"Bottlenecked\" samples indicates fleet-wide efficiency issues:\n",
    "- **< 10% bottlenecked**: Normal operating conditions\n",
    "- **10-20% bottlenecked**: Some workloads need attention\n",
    "- **> 20% bottlenecked**: Systemic data/I/O issues requiring immediate investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate Imbalance Metrics\n",
    "\n",
    "Compute demand-versus-capacity imbalance metrics by joining all data sources:\n",
    "\n",
    "- **Demand Capacity Ratio (DCR)**: pending_workloads / available_capacity\n",
    "- **Queue Pressure Score (QPS)**: Composite of pending + wait time\n",
    "- **Composite Imbalance Score (CIS)**: Overall imbalance indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate imbalance metrics\n",
    "imbalance_df = calculate_all_imbalance_metrics(kueue_df, dcgm_df, nodepool_df)\n",
    "\n",
    "print(f\"Imbalance Analysis: {len(imbalance_df):,} observations\")\n",
    "print(f\"  (aggregated by timestamp_hour × nodegroup)\")\n",
    "\n",
    "print(\"\\nImbalance Metrics Summary:\")\n",
    "print(f\"  Demand-Capacity Ratio (DCR):\")\n",
    "print(f\"    Mean: {imbalance_df['demand_capacity_ratio'].mean():.2f}\")\n",
    "print(f\"    Max:  {imbalance_df['demand_capacity_ratio'].max():.2f}\")\n",
    "print(f\"  Queue Pressure Score (QPS):\")\n",
    "print(f\"    Mean: {imbalance_df['queue_pressure_score'].mean():.3f}\")\n",
    "print(f\"  Composite Imbalance Score (CIS):\")\n",
    "print(f\"    Mean: {imbalance_df['composite_imbalance_score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance severity distribution\n",
    "print(\"Imbalance Severity Distribution:\")\n",
    "print(\"-\" * 40)\n",
    "for sev, count in imbalance_df['imbalance_severity'].value_counts().items():\n",
    "    pct = count / len(imbalance_df) * 100\n",
    "    print(f\"  {sev:10} {count:>6,} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization: Imbalance Heatmap by Nodegroup\n",
    "\n",
    "Shows where and when imbalances occur across the fleet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_imbalance_heatmap(imbalance_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So What?\n",
    "\n",
    "- **Horizontal red bands**: Persistent issues with specific nodegroups (capacity problem)\n",
    "- **Vertical red bands**: Fleet-wide events affecting all nodegroups (demand spike)\n",
    "- **Scattered red cells**: Transient issues, less concerning\n",
    "\n",
    "**Action**: Focus optimization efforts on nodegroups with sustained high imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization: Demand vs Capacity Time Series\n",
    "\n",
    "Three-panel view showing trends over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to fleet-wide time series\n",
    "fleet_ts = create_time_series_summary(imbalance_df)\n",
    "\n",
    "fig = plot_demand_vs_capacity_timeseries(fleet_ts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So What?\n",
    "\n",
    "- **Top panel**: When red (pending) exceeds green (capacity), expect queue growth\n",
    "- **Middle panel**: Gap between utilization and RFU reveals hidden waste\n",
    "- **Bottom panel**: Composite score crossing thresholds signals action needed\n",
    "\n",
    "**Action**: Investigate time periods with sustained high imbalance scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Identify Top Contributors\n",
    "\n",
    "Which nodegroups, queues, and namespaces contribute most to imbalance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributors = identify_top_contributors(imbalance_df, kueue_df, n_top=5)\n",
    "\n",
    "fig = plot_top_contributors(contributors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top Contributing Nodegroups:\")\n",
    "print(contributors['by_nodegroup'].to_string(index=False))\n",
    "print(\"\\nTop Contributing Queues:\")\n",
    "print(contributors['by_queue'][['queue_name', 'pending_workloads', 'admission_wait_time_seconds', 'queue_pressure']].to_string(index=False))\n",
    "print(\"\\nTop Contributing Namespaces:\")\n",
    "print(contributors['by_namespace'][['namespace', 'pending_workloads', 'namespace_pressure']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So What?\n",
    "\n",
    "These are the primary sources of demand-capacity imbalance. Optimization efforts should focus here:\n",
    "\n",
    "1. **High-pressure nodegroups**: May need capacity scaling or workload redistribution\n",
    "2. **High-pressure queues**: Review admission policies, consider priority adjustments\n",
    "3. **High-pressure namespaces**: Engage with teams to optimize workloads or adjust quotas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Recommended Actions\n",
    "\n",
    "Based on the analysis, here are the key findings and recommended actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Key metrics\n",
    "avg_dcr = imbalance_df['demand_capacity_ratio'].mean()\n",
    "avg_cis = imbalance_df['composite_imbalance_score'].mean()\n",
    "avg_gap = dcgm_df['efficiency_gap'].mean()\n",
    "bottleneck_pct = (dcgm_df['efficiency_class'] == 'Bottlenecked').sum() / len(dcgm_df) * 100\n",
    "\n",
    "print(f\"\\n1. DEMAND-CAPACITY BALANCE\")\n",
    "print(f\"   Average DCR: {avg_dcr:.2f}\")\n",
    "if avg_dcr > 1.0:\n",
    "    print(f\"   ⚠️  ALERT: Demand exceeds capacity on average!\")\n",
    "elif avg_dcr > 0.7:\n",
    "    print(f\"   ⚡ WARNING: Approaching capacity limits\")\n",
    "else:\n",
    "    print(f\"   ✅ Healthy: Capacity exceeds demand\")\n",
    "\n",
    "print(f\"\\n2. EFFICIENCY\")\n",
    "print(f\"   Average Efficiency Gap: {avg_gap:.1f} percentage points\")\n",
    "print(f\"   Bottlenecked Samples: {bottleneck_pct:.1f}%\")\n",
    "if avg_gap > 15:\n",
    "    print(f\"   ⚠️  ALERT: Significant hidden inefficiency!\")\n",
    "elif avg_gap > 8:\n",
    "    print(f\"   ⚡ WARNING: Some workloads may be data-starved\")\n",
    "else:\n",
    "    print(f\"   ✅ Healthy: Workloads are generally productive\")\n",
    "\n",
    "print(f\"\\n3. OVERALL IMBALANCE\")\n",
    "print(f\"   Average Composite Score: {avg_cis:.3f}\")\n",
    "if avg_cis > 0.5:\n",
    "    print(f\"   ⚠️  ALERT: Significant imbalance detected!\")\n",
    "elif avg_cis > 0.3:\n",
    "    print(f\"   ⚡ WARNING: Minor imbalances present\")\n",
    "else:\n",
    "    print(f\"   ✅ Healthy: Well-balanced operation\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"RECOMMENDED ACTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Generate recommendations\n",
    "top_ng = contributors['by_nodegroup'].iloc[0]['nodegroup'] if len(contributors['by_nodegroup']) > 0 else 'N/A'\n",
    "top_q = contributors['by_queue'].iloc[0]['queue_name'] if len(contributors['by_queue']) > 0 else 'N/A'\n",
    "\n",
    "print(f\"\\n1. INVESTIGATE: {top_ng}\")\n",
    "print(f\"   This nodegroup shows highest imbalance. Check:\")\n",
    "print(f\"   - Is capacity scaling needed?\")\n",
    "print(f\"   - Are workloads right-sized?\")\n",
    "\n",
    "print(f\"\\n2. REVIEW QUEUE: {top_q}\")\n",
    "print(f\"   This queue has highest pressure. Consider:\")\n",
    "print(f\"   - Adjusting admission policies\")\n",
    "print(f\"   - Redistributing workloads\")\n",
    "\n",
    "if bottleneck_pct > 15:\n",
    "    print(f\"\\n3. OPTIMIZE DATA PIPELINES\")\n",
    "    print(f\"   {bottleneck_pct:.1f}% of GPUs are bottlenecked.\")\n",
    "    print(f\"   - Review data loading patterns\")\n",
    "    print(f\"   - Consider data caching/pre-fetching\")\n",
    "    print(f\"   - Check storage throughput\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. What Additional Data Would Help?\n",
    "\n",
    "This analysis would benefit from:\n",
    "\n",
    "1. **Workload metadata**: Job duration, GPU count per job, completion rates\n",
    "2. **Storage metrics**: I/O throughput, latency to identify data bottlenecks\n",
    "3. **Network metrics**: Bandwidth utilization for distributed training\n",
    "4. **Cost data**: GPU-hour costs for ROI calculations\n",
    "5. **Historical capacity changes**: Autoscaling events for correlation\n",
    "\n",
    "See [docs/ASSUMPTIONS.md](../docs/ASSUMPTIONS.md) for full list of limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Reproduction Steps\n",
    "\n",
    "To reproduce this analysis:\n",
    "\n",
    "```bash\n",
    "# 1. Generate synthetic data\n",
    "python -m src.generators.synthetic_generator --scenario balanced --seed 42 --days 7\n",
    "\n",
    "# 2. Run this notebook\n",
    "jupyter notebook notebooks/demand_capacity_analysis.ipynb\n",
    "```\n",
    "\n",
    "To try different scenarios:\n",
    "```bash\n",
    "python -m src.generators.synthetic_generator --scenario demand_exceeds_capacity\n",
    "python -m src.generators.synthetic_generator --scenario capacity_fragmentation\n",
    "python -m src.generators.synthetic_generator --scenario io_bottleneck\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAnalysis complete!\")\n",
    "print(\"\\nFor questions or feedback, see CONTRIBUTING.md\")\n",
    "print(\"To propose metric changes, use docs/rfcs/RFC_TEMPLATE.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
